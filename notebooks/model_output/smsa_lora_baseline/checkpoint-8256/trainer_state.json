{
  "best_global_step": 8256,
  "best_metric": 0.586,
  "best_model_checkpoint": "model_output/smsa_lora_baseline\\checkpoint-8256",
  "epoch": 24.0,
  "eval_steps": 500,
  "global_step": 8256,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.14534883720930233,
      "grad_norm": 0.8404837250709534,
      "learning_rate": 0.000497625968992248,
      "loss": 0.925,
      "step": 50
    },
    {
      "epoch": 0.29069767441860467,
      "grad_norm": 2.9631404876708984,
      "learning_rate": 0.000495203488372093,
      "loss": 0.7841,
      "step": 100
    },
    {
      "epoch": 0.436046511627907,
      "grad_norm": 1.467084527015686,
      "learning_rate": 0.0004927810077519381,
      "loss": 0.7127,
      "step": 150
    },
    {
      "epoch": 0.5813953488372093,
      "grad_norm": 1.5068366527557373,
      "learning_rate": 0.000490358527131783,
      "loss": 0.7206,
      "step": 200
    },
    {
      "epoch": 0.7267441860465116,
      "grad_norm": 1.2729918956756592,
      "learning_rate": 0.00048793604651162795,
      "loss": 0.6896,
      "step": 250
    },
    {
      "epoch": 0.872093023255814,
      "grad_norm": 1.3377997875213623,
      "learning_rate": 0.00048551356589147287,
      "loss": 0.6869,
      "step": 300
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.404,
      "eval_loss": 1.142369270324707,
      "eval_runtime": 1.3318,
      "eval_samples_per_second": 375.426,
      "eval_steps_per_second": 12.014,
      "step": 344
    },
    {
      "epoch": 1.0174418604651163,
      "grad_norm": 1.091247797012329,
      "learning_rate": 0.00048309108527131784,
      "loss": 0.6792,
      "step": 350
    },
    {
      "epoch": 1.1627906976744187,
      "grad_norm": 1.473922610282898,
      "learning_rate": 0.0004806686046511628,
      "loss": 0.6187,
      "step": 400
    },
    {
      "epoch": 1.308139534883721,
      "grad_norm": 1.2542890310287476,
      "learning_rate": 0.0004782461240310078,
      "loss": 0.5817,
      "step": 450
    },
    {
      "epoch": 1.4534883720930232,
      "grad_norm": 2.4035496711730957,
      "learning_rate": 0.0004758236434108527,
      "loss": 0.5948,
      "step": 500
    },
    {
      "epoch": 1.5988372093023255,
      "grad_norm": 2.0021870136260986,
      "learning_rate": 0.0004734011627906977,
      "loss": 0.593,
      "step": 550
    },
    {
      "epoch": 1.744186046511628,
      "grad_norm": 1.532126545906067,
      "learning_rate": 0.00047097868217054265,
      "loss": 0.5855,
      "step": 600
    },
    {
      "epoch": 1.8895348837209303,
      "grad_norm": 1.1481634378433228,
      "learning_rate": 0.00046855620155038756,
      "loss": 0.6029,
      "step": 650
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.48,
      "eval_loss": 1.0799007415771484,
      "eval_runtime": 1.2349,
      "eval_samples_per_second": 404.903,
      "eval_steps_per_second": 12.957,
      "step": 688
    },
    {
      "epoch": 2.0348837209302326,
      "grad_norm": 1.6303693056106567,
      "learning_rate": 0.00046613372093023254,
      "loss": 0.5811,
      "step": 700
    },
    {
      "epoch": 2.1802325581395348,
      "grad_norm": 1.0653364658355713,
      "learning_rate": 0.00046371124031007756,
      "loss": 0.5388,
      "step": 750
    },
    {
      "epoch": 2.3255813953488373,
      "grad_norm": 1.2070119380950928,
      "learning_rate": 0.00046128875968992253,
      "loss": 0.5795,
      "step": 800
    },
    {
      "epoch": 2.4709302325581395,
      "grad_norm": 1.138908863067627,
      "learning_rate": 0.00045886627906976745,
      "loss": 0.5602,
      "step": 850
    },
    {
      "epoch": 2.616279069767442,
      "grad_norm": 3.910853147506714,
      "learning_rate": 0.0004564437984496124,
      "loss": 0.5606,
      "step": 900
    },
    {
      "epoch": 2.761627906976744,
      "grad_norm": 1.4455384016036987,
      "learning_rate": 0.0004540213178294574,
      "loss": 0.5631,
      "step": 950
    },
    {
      "epoch": 2.9069767441860463,
      "grad_norm": 1.7642778158187866,
      "learning_rate": 0.0004515988372093023,
      "loss": 0.5425,
      "step": 1000
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.506,
      "eval_loss": 1.0146775245666504,
      "eval_runtime": 1.7984,
      "eval_samples_per_second": 278.024,
      "eval_steps_per_second": 8.897,
      "step": 1032
    },
    {
      "epoch": 3.052325581395349,
      "grad_norm": 2.120061159133911,
      "learning_rate": 0.0004491763565891473,
      "loss": 0.5346,
      "step": 1050
    },
    {
      "epoch": 3.197674418604651,
      "grad_norm": 1.6051721572875977,
      "learning_rate": 0.00044675387596899226,
      "loss": 0.5262,
      "step": 1100
    },
    {
      "epoch": 3.3430232558139537,
      "grad_norm": 1.4291598796844482,
      "learning_rate": 0.00044433139534883723,
      "loss": 0.5573,
      "step": 1150
    },
    {
      "epoch": 3.488372093023256,
      "grad_norm": 1.463029146194458,
      "learning_rate": 0.00044190891472868215,
      "loss": 0.5232,
      "step": 1200
    },
    {
      "epoch": 3.633720930232558,
      "grad_norm": 1.4474384784698486,
      "learning_rate": 0.0004394864341085271,
      "loss": 0.5193,
      "step": 1250
    },
    {
      "epoch": 3.7790697674418605,
      "grad_norm": 2.646670341491699,
      "learning_rate": 0.0004370639534883721,
      "loss": 0.5412,
      "step": 1300
    },
    {
      "epoch": 3.9244186046511627,
      "grad_norm": 2.5519094467163086,
      "learning_rate": 0.000434641472868217,
      "loss": 0.5869,
      "step": 1350
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.53,
      "eval_loss": 1.0180147886276245,
      "eval_runtime": 1.1495,
      "eval_samples_per_second": 434.975,
      "eval_steps_per_second": 13.919,
      "step": 1376
    },
    {
      "epoch": 4.069767441860465,
      "grad_norm": 1.4162778854370117,
      "learning_rate": 0.00043221899224806204,
      "loss": 0.5443,
      "step": 1400
    },
    {
      "epoch": 4.215116279069767,
      "grad_norm": 1.444473385810852,
      "learning_rate": 0.000429796511627907,
      "loss": 0.5019,
      "step": 1450
    },
    {
      "epoch": 4.3604651162790695,
      "grad_norm": 1.738884449005127,
      "learning_rate": 0.000427374031007752,
      "loss": 0.5445,
      "step": 1500
    },
    {
      "epoch": 4.5058139534883725,
      "grad_norm": 2.35835862159729,
      "learning_rate": 0.0004249515503875969,
      "loss": 0.5199,
      "step": 1550
    },
    {
      "epoch": 4.651162790697675,
      "grad_norm": 1.352653980255127,
      "learning_rate": 0.00042252906976744187,
      "loss": 0.5349,
      "step": 1600
    },
    {
      "epoch": 4.796511627906977,
      "grad_norm": 1.279197335243225,
      "learning_rate": 0.00042010658914728684,
      "loss": 0.516,
      "step": 1650
    },
    {
      "epoch": 4.941860465116279,
      "grad_norm": 1.3406318426132202,
      "learning_rate": 0.0004176841085271318,
      "loss": 0.5466,
      "step": 1700
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.508,
      "eval_loss": 1.0388604402542114,
      "eval_runtime": 1.2822,
      "eval_samples_per_second": 389.96,
      "eval_steps_per_second": 12.479,
      "step": 1720
    },
    {
      "epoch": 5.087209302325581,
      "grad_norm": 2.091301202774048,
      "learning_rate": 0.00041526162790697673,
      "loss": 0.524,
      "step": 1750
    },
    {
      "epoch": 5.232558139534884,
      "grad_norm": 2.2331111431121826,
      "learning_rate": 0.0004128391472868217,
      "loss": 0.5381,
      "step": 1800
    },
    {
      "epoch": 5.377906976744186,
      "grad_norm": 1.365658164024353,
      "learning_rate": 0.0004104166666666667,
      "loss": 0.5368,
      "step": 1850
    },
    {
      "epoch": 5.523255813953488,
      "grad_norm": 2.243084192276001,
      "learning_rate": 0.0004079941860465116,
      "loss": 0.5377,
      "step": 1900
    },
    {
      "epoch": 5.6686046511627906,
      "grad_norm": 1.8626348972320557,
      "learning_rate": 0.00040557170542635657,
      "loss": 0.4865,
      "step": 1950
    },
    {
      "epoch": 5.813953488372093,
      "grad_norm": 2.288147211074829,
      "learning_rate": 0.00040314922480620154,
      "loss": 0.4958,
      "step": 2000
    },
    {
      "epoch": 5.959302325581396,
      "grad_norm": 3.336984157562256,
      "learning_rate": 0.00040072674418604657,
      "loss": 0.5408,
      "step": 2050
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.546,
      "eval_loss": 0.9991551637649536,
      "eval_runtime": 1.4207,
      "eval_samples_per_second": 351.934,
      "eval_steps_per_second": 11.262,
      "step": 2064
    },
    {
      "epoch": 6.104651162790698,
      "grad_norm": 1.7640892267227173,
      "learning_rate": 0.0003983042635658915,
      "loss": 0.517,
      "step": 2100
    },
    {
      "epoch": 6.25,
      "grad_norm": 1.5133126974105835,
      "learning_rate": 0.00039588178294573646,
      "loss": 0.5227,
      "step": 2150
    },
    {
      "epoch": 6.395348837209302,
      "grad_norm": 1.6615262031555176,
      "learning_rate": 0.00039345930232558143,
      "loss": 0.5311,
      "step": 2200
    },
    {
      "epoch": 6.540697674418604,
      "grad_norm": 2.3673155307769775,
      "learning_rate": 0.00039103682170542635,
      "loss": 0.483,
      "step": 2250
    },
    {
      "epoch": 6.686046511627907,
      "grad_norm": 1.34617280960083,
      "learning_rate": 0.0003886143410852713,
      "loss": 0.5369,
      "step": 2300
    },
    {
      "epoch": 6.8313953488372094,
      "grad_norm": 1.0357534885406494,
      "learning_rate": 0.0003861918604651163,
      "loss": 0.501,
      "step": 2350
    },
    {
      "epoch": 6.976744186046512,
      "grad_norm": 1.4194109439849854,
      "learning_rate": 0.00038376937984496126,
      "loss": 0.5302,
      "step": 2400
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.504,
      "eval_loss": 1.076570749282837,
      "eval_runtime": 1.1767,
      "eval_samples_per_second": 424.901,
      "eval_steps_per_second": 13.597,
      "step": 2408
    },
    {
      "epoch": 7.122093023255814,
      "grad_norm": 2.205284595489502,
      "learning_rate": 0.0003813468992248062,
      "loss": 0.5286,
      "step": 2450
    },
    {
      "epoch": 7.267441860465116,
      "grad_norm": 4.109543323516846,
      "learning_rate": 0.00037892441860465115,
      "loss": 0.4936,
      "step": 2500
    },
    {
      "epoch": 7.412790697674419,
      "grad_norm": 1.1412557363510132,
      "learning_rate": 0.0003765019379844961,
      "loss": 0.5091,
      "step": 2550
    },
    {
      "epoch": 7.558139534883721,
      "grad_norm": 1.232033610343933,
      "learning_rate": 0.0003740794573643411,
      "loss": 0.522,
      "step": 2600
    },
    {
      "epoch": 7.703488372093023,
      "grad_norm": 1.339621663093567,
      "learning_rate": 0.00037165697674418607,
      "loss": 0.4902,
      "step": 2650
    },
    {
      "epoch": 7.848837209302325,
      "grad_norm": 1.7895431518554688,
      "learning_rate": 0.00036923449612403104,
      "loss": 0.4972,
      "step": 2700
    },
    {
      "epoch": 7.9941860465116275,
      "grad_norm": 2.127431869506836,
      "learning_rate": 0.000366812015503876,
      "loss": 0.521,
      "step": 2750
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.518,
      "eval_loss": 1.0907057523727417,
      "eval_runtime": 1.574,
      "eval_samples_per_second": 317.661,
      "eval_steps_per_second": 10.165,
      "step": 2752
    },
    {
      "epoch": 8.13953488372093,
      "grad_norm": 1.346320629119873,
      "learning_rate": 0.00036438953488372093,
      "loss": 0.4917,
      "step": 2800
    },
    {
      "epoch": 8.284883720930232,
      "grad_norm": 1.7059351205825806,
      "learning_rate": 0.0003619670542635659,
      "loss": 0.5013,
      "step": 2850
    },
    {
      "epoch": 8.430232558139535,
      "grad_norm": 2.304042100906372,
      "learning_rate": 0.0003595445736434109,
      "loss": 0.5308,
      "step": 2900
    },
    {
      "epoch": 8.575581395348838,
      "grad_norm": 1.8458528518676758,
      "learning_rate": 0.00035712209302325585,
      "loss": 0.5083,
      "step": 2950
    },
    {
      "epoch": 8.720930232558139,
      "grad_norm": 2.59736967086792,
      "learning_rate": 0.00035469961240310076,
      "loss": 0.5074,
      "step": 3000
    },
    {
      "epoch": 8.866279069767442,
      "grad_norm": 2.2718443870544434,
      "learning_rate": 0.00035227713178294574,
      "loss": 0.5041,
      "step": 3050
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.546,
      "eval_loss": 1.028499722480774,
      "eval_runtime": 1.1041,
      "eval_samples_per_second": 452.839,
      "eval_steps_per_second": 14.491,
      "step": 3096
    },
    {
      "epoch": 9.011627906976743,
      "grad_norm": 1.1439414024353027,
      "learning_rate": 0.0003498546511627907,
      "loss": 0.499,
      "step": 3100
    },
    {
      "epoch": 9.156976744186046,
      "grad_norm": 1.1476011276245117,
      "learning_rate": 0.0003474321705426356,
      "loss": 0.4807,
      "step": 3150
    },
    {
      "epoch": 9.30232558139535,
      "grad_norm": 1.3153070211410522,
      "learning_rate": 0.0003450096899224806,
      "loss": 0.4849,
      "step": 3200
    },
    {
      "epoch": 9.44767441860465,
      "grad_norm": 1.671693205833435,
      "learning_rate": 0.00034258720930232557,
      "loss": 0.4778,
      "step": 3250
    },
    {
      "epoch": 9.593023255813954,
      "grad_norm": 1.9701443910598755,
      "learning_rate": 0.0003401647286821706,
      "loss": 0.528,
      "step": 3300
    },
    {
      "epoch": 9.738372093023255,
      "grad_norm": 2.170929193496704,
      "learning_rate": 0.0003377422480620155,
      "loss": 0.4941,
      "step": 3350
    },
    {
      "epoch": 9.883720930232558,
      "grad_norm": 1.8952194452285767,
      "learning_rate": 0.0003353197674418605,
      "loss": 0.5383,
      "step": 3400
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.546,
      "eval_loss": 1.027349591255188,
      "eval_runtime": 1.1954,
      "eval_samples_per_second": 418.282,
      "eval_steps_per_second": 13.385,
      "step": 3440
    },
    {
      "epoch": 10.029069767441861,
      "grad_norm": 0.940096914768219,
      "learning_rate": 0.00033289728682170546,
      "loss": 0.508,
      "step": 3450
    },
    {
      "epoch": 10.174418604651162,
      "grad_norm": 1.7760790586471558,
      "learning_rate": 0.0003304748062015504,
      "loss": 0.5095,
      "step": 3500
    },
    {
      "epoch": 10.319767441860465,
      "grad_norm": 3.3575196266174316,
      "learning_rate": 0.00032805232558139535,
      "loss": 0.4879,
      "step": 3550
    },
    {
      "epoch": 10.465116279069768,
      "grad_norm": 1.3082555532455444,
      "learning_rate": 0.0003256298449612403,
      "loss": 0.4784,
      "step": 3600
    },
    {
      "epoch": 10.61046511627907,
      "grad_norm": 1.0702416896820068,
      "learning_rate": 0.0003232073643410853,
      "loss": 0.4707,
      "step": 3650
    },
    {
      "epoch": 10.755813953488373,
      "grad_norm": 1.0579261779785156,
      "learning_rate": 0.0003207848837209302,
      "loss": 0.5223,
      "step": 3700
    },
    {
      "epoch": 10.901162790697674,
      "grad_norm": 1.0888639688491821,
      "learning_rate": 0.0003183624031007752,
      "loss": 0.4788,
      "step": 3750
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.546,
      "eval_loss": 1.0797789096832275,
      "eval_runtime": 1.5087,
      "eval_samples_per_second": 331.408,
      "eval_steps_per_second": 10.605,
      "step": 3784
    },
    {
      "epoch": 11.046511627906977,
      "grad_norm": 2.805402994155884,
      "learning_rate": 0.00031593992248062016,
      "loss": 0.4882,
      "step": 3800
    },
    {
      "epoch": 11.19186046511628,
      "grad_norm": 2.392232894897461,
      "learning_rate": 0.00031351744186046513,
      "loss": 0.4855,
      "step": 3850
    },
    {
      "epoch": 11.337209302325581,
      "grad_norm": 1.7806477546691895,
      "learning_rate": 0.00031109496124031005,
      "loss": 0.5253,
      "step": 3900
    },
    {
      "epoch": 11.482558139534884,
      "grad_norm": 2.7486934661865234,
      "learning_rate": 0.00030867248062015507,
      "loss": 0.4733,
      "step": 3950
    },
    {
      "epoch": 11.627906976744185,
      "grad_norm": 2.3483059406280518,
      "learning_rate": 0.00030625000000000004,
      "loss": 0.4837,
      "step": 4000
    },
    {
      "epoch": 11.773255813953488,
      "grad_norm": 1.3913426399230957,
      "learning_rate": 0.00030382751937984496,
      "loss": 0.4764,
      "step": 4050
    },
    {
      "epoch": 11.918604651162791,
      "grad_norm": 2.638359308242798,
      "learning_rate": 0.00030140503875968993,
      "loss": 0.4973,
      "step": 4100
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.558,
      "eval_loss": 1.038668155670166,
      "eval_runtime": 1.3919,
      "eval_samples_per_second": 359.214,
      "eval_steps_per_second": 11.495,
      "step": 4128
    },
    {
      "epoch": 12.063953488372093,
      "grad_norm": 1.8584870100021362,
      "learning_rate": 0.0002989825581395349,
      "loss": 0.4731,
      "step": 4150
    },
    {
      "epoch": 12.209302325581396,
      "grad_norm": 2.515749931335449,
      "learning_rate": 0.0002965600775193799,
      "loss": 0.5203,
      "step": 4200
    },
    {
      "epoch": 12.354651162790697,
      "grad_norm": 2.2413551807403564,
      "learning_rate": 0.0002941375968992248,
      "loss": 0.4825,
      "step": 4250
    },
    {
      "epoch": 12.5,
      "grad_norm": 1.9940571784973145,
      "learning_rate": 0.00029171511627906977,
      "loss": 0.4803,
      "step": 4300
    },
    {
      "epoch": 12.645348837209303,
      "grad_norm": 1.2978538274765015,
      "learning_rate": 0.00028929263565891474,
      "loss": 0.4769,
      "step": 4350
    },
    {
      "epoch": 12.790697674418604,
      "grad_norm": 1.8143525123596191,
      "learning_rate": 0.00028687015503875966,
      "loss": 0.4762,
      "step": 4400
    },
    {
      "epoch": 12.936046511627907,
      "grad_norm": 1.800936222076416,
      "learning_rate": 0.00028444767441860463,
      "loss": 0.5027,
      "step": 4450
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.572,
      "eval_loss": 1.0132282972335815,
      "eval_runtime": 1.2327,
      "eval_samples_per_second": 405.617,
      "eval_steps_per_second": 12.98,
      "step": 4472
    },
    {
      "epoch": 13.081395348837209,
      "grad_norm": 2.3215363025665283,
      "learning_rate": 0.0002820251937984496,
      "loss": 0.4692,
      "step": 4500
    },
    {
      "epoch": 13.226744186046512,
      "grad_norm": 2.553581714630127,
      "learning_rate": 0.0002796027131782946,
      "loss": 0.4798,
      "step": 4550
    },
    {
      "epoch": 13.372093023255815,
      "grad_norm": 1.3597415685653687,
      "learning_rate": 0.00027718023255813955,
      "loss": 0.4746,
      "step": 4600
    },
    {
      "epoch": 13.517441860465116,
      "grad_norm": 1.1586424112319946,
      "learning_rate": 0.0002747577519379845,
      "loss": 0.4829,
      "step": 4650
    },
    {
      "epoch": 13.662790697674419,
      "grad_norm": 1.457834005355835,
      "learning_rate": 0.0002723352713178295,
      "loss": 0.4498,
      "step": 4700
    },
    {
      "epoch": 13.80813953488372,
      "grad_norm": 2.139923572540283,
      "learning_rate": 0.00026991279069767446,
      "loss": 0.4979,
      "step": 4750
    },
    {
      "epoch": 13.953488372093023,
      "grad_norm": 1.7004802227020264,
      "learning_rate": 0.0002674903100775194,
      "loss": 0.4842,
      "step": 4800
    },
    {
      "epoch": 14.0,
      "eval_accuracy": 0.566,
      "eval_loss": 1.0176714658737183,
      "eval_runtime": 1.4207,
      "eval_samples_per_second": 351.939,
      "eval_steps_per_second": 11.262,
      "step": 4816
    },
    {
      "epoch": 14.098837209302326,
      "grad_norm": 1.1772985458374023,
      "learning_rate": 0.00026506782945736435,
      "loss": 0.4926,
      "step": 4850
    },
    {
      "epoch": 14.244186046511627,
      "grad_norm": 1.6832188367843628,
      "learning_rate": 0.0002626453488372093,
      "loss": 0.4664,
      "step": 4900
    },
    {
      "epoch": 14.38953488372093,
      "grad_norm": 2.6831142902374268,
      "learning_rate": 0.00026022286821705424,
      "loss": 0.4892,
      "step": 4950
    },
    {
      "epoch": 14.534883720930232,
      "grad_norm": 1.7616842985153198,
      "learning_rate": 0.0002578003875968992,
      "loss": 0.4585,
      "step": 5000
    },
    {
      "epoch": 14.680232558139535,
      "grad_norm": 1.2021784782409668,
      "learning_rate": 0.0002553779069767442,
      "loss": 0.4824,
      "step": 5050
    },
    {
      "epoch": 14.825581395348838,
      "grad_norm": 2.127458333969116,
      "learning_rate": 0.00025295542635658916,
      "loss": 0.4736,
      "step": 5100
    },
    {
      "epoch": 14.970930232558139,
      "grad_norm": 1.0171762704849243,
      "learning_rate": 0.0002505329457364341,
      "loss": 0.4857,
      "step": 5150
    },
    {
      "epoch": 15.0,
      "eval_accuracy": 0.578,
      "eval_loss": 1.0278569459915161,
      "eval_runtime": 1.4538,
      "eval_samples_per_second": 343.919,
      "eval_steps_per_second": 11.005,
      "step": 5160
    },
    {
      "epoch": 15.116279069767442,
      "grad_norm": 1.8775650262832642,
      "learning_rate": 0.0002481104651162791,
      "loss": 0.4602,
      "step": 5200
    },
    {
      "epoch": 15.261627906976745,
      "grad_norm": 1.9704465866088867,
      "learning_rate": 0.000245687984496124,
      "loss": 0.4587,
      "step": 5250
    },
    {
      "epoch": 15.406976744186046,
      "grad_norm": 2.112821102142334,
      "learning_rate": 0.000243265503875969,
      "loss": 0.4962,
      "step": 5300
    },
    {
      "epoch": 15.55232558139535,
      "grad_norm": 0.9371416568756104,
      "learning_rate": 0.00024084302325581394,
      "loss": 0.4662,
      "step": 5350
    },
    {
      "epoch": 15.69767441860465,
      "grad_norm": 1.7172967195510864,
      "learning_rate": 0.00023842054263565894,
      "loss": 0.4734,
      "step": 5400
    },
    {
      "epoch": 15.843023255813954,
      "grad_norm": 2.142672538757324,
      "learning_rate": 0.00023599806201550388,
      "loss": 0.4873,
      "step": 5450
    },
    {
      "epoch": 15.988372093023255,
      "grad_norm": 2.500450372695923,
      "learning_rate": 0.00023357558139534886,
      "loss": 0.47,
      "step": 5500
    },
    {
      "epoch": 16.0,
      "eval_accuracy": 0.582,
      "eval_loss": 1.0016487836837769,
      "eval_runtime": 1.29,
      "eval_samples_per_second": 387.607,
      "eval_steps_per_second": 12.403,
      "step": 5504
    },
    {
      "epoch": 16.13372093023256,
      "grad_norm": 2.6920604705810547,
      "learning_rate": 0.0002311531007751938,
      "loss": 0.4871,
      "step": 5550
    },
    {
      "epoch": 16.27906976744186,
      "grad_norm": 1.3702397346496582,
      "learning_rate": 0.00022873062015503877,
      "loss": 0.4942,
      "step": 5600
    },
    {
      "epoch": 16.424418604651162,
      "grad_norm": 1.8430180549621582,
      "learning_rate": 0.00022630813953488372,
      "loss": 0.4637,
      "step": 5650
    },
    {
      "epoch": 16.569767441860463,
      "grad_norm": 1.3084505796432495,
      "learning_rate": 0.00022388565891472866,
      "loss": 0.4752,
      "step": 5700
    },
    {
      "epoch": 16.71511627906977,
      "grad_norm": 2.395430326461792,
      "learning_rate": 0.00022146317829457366,
      "loss": 0.4705,
      "step": 5750
    },
    {
      "epoch": 16.86046511627907,
      "grad_norm": 3.269843101501465,
      "learning_rate": 0.0002190406976744186,
      "loss": 0.4592,
      "step": 5800
    },
    {
      "epoch": 17.0,
      "eval_accuracy": 0.566,
      "eval_loss": 1.038785457611084,
      "eval_runtime": 1.2668,
      "eval_samples_per_second": 394.697,
      "eval_steps_per_second": 12.63,
      "step": 5848
    },
    {
      "epoch": 17.00581395348837,
      "grad_norm": 1.5005309581756592,
      "learning_rate": 0.00021661821705426358,
      "loss": 0.4843,
      "step": 5850
    },
    {
      "epoch": 17.151162790697676,
      "grad_norm": 1.2565958499908447,
      "learning_rate": 0.00021419573643410852,
      "loss": 0.4558,
      "step": 5900
    },
    {
      "epoch": 17.296511627906977,
      "grad_norm": 1.3429831266403198,
      "learning_rate": 0.0002117732558139535,
      "loss": 0.4787,
      "step": 5950
    },
    {
      "epoch": 17.441860465116278,
      "grad_norm": 1.3495337963104248,
      "learning_rate": 0.00020935077519379844,
      "loss": 0.4515,
      "step": 6000
    },
    {
      "epoch": 17.587209302325583,
      "grad_norm": 1.5181881189346313,
      "learning_rate": 0.00020692829457364344,
      "loss": 0.4732,
      "step": 6050
    },
    {
      "epoch": 17.732558139534884,
      "grad_norm": 1.2379108667373657,
      "learning_rate": 0.00020450581395348839,
      "loss": 0.4797,
      "step": 6100
    },
    {
      "epoch": 17.877906976744185,
      "grad_norm": 1.61046302318573,
      "learning_rate": 0.00020208333333333333,
      "loss": 0.5089,
      "step": 6150
    },
    {
      "epoch": 18.0,
      "eval_accuracy": 0.584,
      "eval_loss": 0.9871819615364075,
      "eval_runtime": 1.3165,
      "eval_samples_per_second": 379.787,
      "eval_steps_per_second": 12.153,
      "step": 6192
    },
    {
      "epoch": 18.023255813953487,
      "grad_norm": 1.1441826820373535,
      "learning_rate": 0.0001996608527131783,
      "loss": 0.447,
      "step": 6200
    },
    {
      "epoch": 18.16860465116279,
      "grad_norm": 2.2494091987609863,
      "learning_rate": 0.00019723837209302325,
      "loss": 0.4698,
      "step": 6250
    },
    {
      "epoch": 18.313953488372093,
      "grad_norm": 2.1352269649505615,
      "learning_rate": 0.00019481589147286822,
      "loss": 0.4729,
      "step": 6300
    },
    {
      "epoch": 18.459302325581394,
      "grad_norm": 2.5530037879943848,
      "learning_rate": 0.00019239341085271316,
      "loss": 0.4607,
      "step": 6350
    },
    {
      "epoch": 18.6046511627907,
      "grad_norm": 1.5628920793533325,
      "learning_rate": 0.00018997093023255816,
      "loss": 0.4613,
      "step": 6400
    },
    {
      "epoch": 18.75,
      "grad_norm": 3.0852530002593994,
      "learning_rate": 0.0001875484496124031,
      "loss": 0.4759,
      "step": 6450
    },
    {
      "epoch": 18.8953488372093,
      "grad_norm": 1.1739503145217896,
      "learning_rate": 0.00018512596899224805,
      "loss": 0.4786,
      "step": 6500
    },
    {
      "epoch": 19.0,
      "eval_accuracy": 0.576,
      "eval_loss": 1.0181769132614136,
      "eval_runtime": 1.1662,
      "eval_samples_per_second": 428.742,
      "eval_steps_per_second": 13.72,
      "step": 6536
    },
    {
      "epoch": 19.040697674418606,
      "grad_norm": 1.7920395135879517,
      "learning_rate": 0.00018270348837209303,
      "loss": 0.4773,
      "step": 6550
    },
    {
      "epoch": 19.186046511627907,
      "grad_norm": 1.1971241235733032,
      "learning_rate": 0.00018028100775193797,
      "loss": 0.4429,
      "step": 6600
    },
    {
      "epoch": 19.33139534883721,
      "grad_norm": 2.7635653018951416,
      "learning_rate": 0.00017785852713178294,
      "loss": 0.4813,
      "step": 6650
    },
    {
      "epoch": 19.476744186046513,
      "grad_norm": 3.7738521099090576,
      "learning_rate": 0.00017543604651162792,
      "loss": 0.462,
      "step": 6700
    },
    {
      "epoch": 19.622093023255815,
      "grad_norm": 1.2683378458023071,
      "learning_rate": 0.0001730135658914729,
      "loss": 0.4973,
      "step": 6750
    },
    {
      "epoch": 19.767441860465116,
      "grad_norm": 1.6123870611190796,
      "learning_rate": 0.00017059108527131783,
      "loss": 0.4888,
      "step": 6800
    },
    {
      "epoch": 19.912790697674417,
      "grad_norm": 1.2285674810409546,
      "learning_rate": 0.0001681686046511628,
      "loss": 0.4544,
      "step": 6850
    },
    {
      "epoch": 20.0,
      "eval_accuracy": 0.57,
      "eval_loss": 1.047926425933838,
      "eval_runtime": 1.2279,
      "eval_samples_per_second": 407.183,
      "eval_steps_per_second": 13.03,
      "step": 6880
    },
    {
      "epoch": 20.058139534883722,
      "grad_norm": 1.2695345878601074,
      "learning_rate": 0.00016574612403100775,
      "loss": 0.4177,
      "step": 6900
    },
    {
      "epoch": 20.203488372093023,
      "grad_norm": 1.63347327709198,
      "learning_rate": 0.0001633236434108527,
      "loss": 0.4682,
      "step": 6950
    },
    {
      "epoch": 20.348837209302324,
      "grad_norm": 1.9108905792236328,
      "learning_rate": 0.0001609011627906977,
      "loss": 0.4658,
      "step": 7000
    },
    {
      "epoch": 20.49418604651163,
      "grad_norm": 1.1970232725143433,
      "learning_rate": 0.00015847868217054264,
      "loss": 0.477,
      "step": 7050
    },
    {
      "epoch": 20.63953488372093,
      "grad_norm": 2.8900258541107178,
      "learning_rate": 0.0001560562015503876,
      "loss": 0.4421,
      "step": 7100
    },
    {
      "epoch": 20.78488372093023,
      "grad_norm": 1.997302532196045,
      "learning_rate": 0.00015363372093023256,
      "loss": 0.4738,
      "step": 7150
    },
    {
      "epoch": 20.930232558139537,
      "grad_norm": 1.7132295370101929,
      "learning_rate": 0.00015121124031007753,
      "loss": 0.4879,
      "step": 7200
    },
    {
      "epoch": 21.0,
      "eval_accuracy": 0.576,
      "eval_loss": 1.0294040441513062,
      "eval_runtime": 1.2002,
      "eval_samples_per_second": 416.611,
      "eval_steps_per_second": 13.332,
      "step": 7224
    },
    {
      "epoch": 21.075581395348838,
      "grad_norm": 1.3527235984802246,
      "learning_rate": 0.00014878875968992247,
      "loss": 0.4572,
      "step": 7250
    },
    {
      "epoch": 21.22093023255814,
      "grad_norm": 2.620760202407837,
      "learning_rate": 0.00014636627906976745,
      "loss": 0.5079,
      "step": 7300
    },
    {
      "epoch": 21.36627906976744,
      "grad_norm": 2.1932199001312256,
      "learning_rate": 0.00014394379844961242,
      "loss": 0.4791,
      "step": 7350
    },
    {
      "epoch": 21.511627906976745,
      "grad_norm": 2.4284462928771973,
      "learning_rate": 0.00014152131782945736,
      "loss": 0.4896,
      "step": 7400
    },
    {
      "epoch": 21.656976744186046,
      "grad_norm": 1.5302022695541382,
      "learning_rate": 0.00013909883720930233,
      "loss": 0.482,
      "step": 7450
    },
    {
      "epoch": 21.802325581395348,
      "grad_norm": 1.8947668075561523,
      "learning_rate": 0.00013667635658914728,
      "loss": 0.4331,
      "step": 7500
    },
    {
      "epoch": 21.947674418604652,
      "grad_norm": 1.701553225517273,
      "learning_rate": 0.00013425387596899225,
      "loss": 0.467,
      "step": 7550
    },
    {
      "epoch": 22.0,
      "eval_accuracy": 0.58,
      "eval_loss": 1.0135579109191895,
      "eval_runtime": 1.354,
      "eval_samples_per_second": 369.266,
      "eval_steps_per_second": 11.817,
      "step": 7568
    },
    {
      "epoch": 22.093023255813954,
      "grad_norm": 2.589752197265625,
      "learning_rate": 0.0001318313953488372,
      "loss": 0.4675,
      "step": 7600
    },
    {
      "epoch": 22.238372093023255,
      "grad_norm": 1.5314241647720337,
      "learning_rate": 0.0001294089147286822,
      "loss": 0.4712,
      "step": 7650
    },
    {
      "epoch": 22.38372093023256,
      "grad_norm": 1.7744563817977905,
      "learning_rate": 0.00012698643410852714,
      "loss": 0.4411,
      "step": 7700
    },
    {
      "epoch": 22.52906976744186,
      "grad_norm": 1.9220926761627197,
      "learning_rate": 0.0001245639534883721,
      "loss": 0.4571,
      "step": 7750
    },
    {
      "epoch": 22.674418604651162,
      "grad_norm": 1.3516740798950195,
      "learning_rate": 0.00012214147286821706,
      "loss": 0.4726,
      "step": 7800
    },
    {
      "epoch": 22.819767441860463,
      "grad_norm": 1.3160954713821411,
      "learning_rate": 0.00011971899224806202,
      "loss": 0.4876,
      "step": 7850
    },
    {
      "epoch": 22.96511627906977,
      "grad_norm": 1.5530438423156738,
      "learning_rate": 0.00011729651162790699,
      "loss": 0.4634,
      "step": 7900
    },
    {
      "epoch": 23.0,
      "eval_accuracy": 0.574,
      "eval_loss": 1.0068142414093018,
      "eval_runtime": 1.197,
      "eval_samples_per_second": 417.714,
      "eval_steps_per_second": 13.367,
      "step": 7912
    },
    {
      "epoch": 23.11046511627907,
      "grad_norm": 1.609380841255188,
      "learning_rate": 0.00011487403100775195,
      "loss": 0.4542,
      "step": 7950
    },
    {
      "epoch": 23.25581395348837,
      "grad_norm": 1.500673770904541,
      "learning_rate": 0.00011245155038759689,
      "loss": 0.4573,
      "step": 8000
    },
    {
      "epoch": 23.401162790697676,
      "grad_norm": 1.5361181497573853,
      "learning_rate": 0.00011002906976744186,
      "loss": 0.455,
      "step": 8050
    },
    {
      "epoch": 23.546511627906977,
      "grad_norm": 0.9239962697029114,
      "learning_rate": 0.00010760658914728682,
      "loss": 0.4721,
      "step": 8100
    },
    {
      "epoch": 23.691860465116278,
      "grad_norm": 1.9129947423934937,
      "learning_rate": 0.00010518410852713178,
      "loss": 0.4647,
      "step": 8150
    },
    {
      "epoch": 23.837209302325583,
      "grad_norm": 1.8123201131820679,
      "learning_rate": 0.00010276162790697674,
      "loss": 0.4798,
      "step": 8200
    },
    {
      "epoch": 23.982558139534884,
      "grad_norm": 1.8800004720687866,
      "learning_rate": 0.00010033914728682171,
      "loss": 0.4527,
      "step": 8250
    },
    {
      "epoch": 24.0,
      "eval_accuracy": 0.586,
      "eval_loss": 0.9867746233940125,
      "eval_runtime": 1.1862,
      "eval_samples_per_second": 421.507,
      "eval_steps_per_second": 13.488,
      "step": 8256
    }
  ],
  "logging_steps": 50,
  "max_steps": 10320,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 30,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 85617709056000.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
